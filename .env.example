# AI Provider Configuration
# Using Ollama (local AI)
# Ollama must be installed and running
# Install: https://ollama.ai
OLLAMA_BASE_URL=http://localhost:11434
# Default model: llama3.1:8b (recommended for job extraction tasks)
# Other options: llama3.2:8b, llama3.1:70b, llama3.2:70b, mistral, etc.
OLLAMA_MODEL=llama3.1:8b

# Application Configuration
APP_HOST=0.0.0.0
APP_PORT=8000
DEBUG_MODE=True

# Excel File Path
# Path to the Excel file containing company data
EXCEL_FILE_PATH=data/Landratsamt.xlsx

# Processing Configuration
MAX_CONCURRENT_REQUESTS=5
REQUEST_TIMEOUT=30

# AI Rate Limiting
# Delay in seconds between AI API calls
# For Ollama (local), you can set this to 0 or 1 since there's no rate limit
AI_RATE_LIMIT_DELAY=0
